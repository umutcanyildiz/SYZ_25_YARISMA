import json
import os
from typing import List, Dict, Any
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
import timm
from PIL import Image
import glob

class CompetitionJSONGenerator:
    """
    YarÄ±ÅŸma iÃ§in model tahminlerini JSON formatÄ±nda hazÄ±rlayan sÄ±nÄ±f
    """
    
    def __init__(self, takim_adi: str, takim_id: str, aciklama: str = "", versiyon: str = "v1.0"):
        """
        JSON generator'Ä± baÅŸlat
        
        Args:
            takim_adi: TakÄ±m ismi
            takim_id: Sistem tarafÄ±ndan verilen takÄ±m numarasÄ±
            aciklama: Modelin amacÄ± veya kÄ±sa aÃ§Ä±klama (opsiyonel)
            versiyon: Tahmin dosyasÄ±nÄ±n versiyonu (opsiyonel)
        """
        self.kunye = {
            "takim_adi": takim_adi,
            "takim_id": takim_id,
            "aciklama": aciklama,
            "versiyon": versiyon
        }
        self.tahminler = []
    
    def add_prediction(self, filename: str, stroke: int, stroke_type: int = 3):
        """
        Tek bir tahmin ekle
        
        Args:
            filename: Dosya adÄ± (uzantÄ±sÄ± ile birlikte, klasÃ¶r yolu olmadan)
            stroke: Ä°nme durumu (0: yok, 1: var) - int formatÄ±nda
            stroke_type: Ä°nme tipi (0: iskemik, 1: kanamalÄ±, 3: belirsiz/bilinmiyor)
        """
        # Dosya adÄ±nÄ±n sadece isim+uzantÄ± olduÄŸundan emin ol
        filename = os.path.basename(filename)
        
        # stroke deÄŸerinin int olduÄŸundan emin ol
        if isinstance(stroke, (float, np.floating)):
            stroke = int(stroke)
        elif isinstance(stroke, str):
            stroke = int(float(stroke))
        
        # stroke_type deÄŸerinin int olduÄŸundan emin ol
        if isinstance(stroke_type, (float, np.floating)):
            stroke_type = int(stroke_type)
        elif isinstance(stroke_type, str):
            stroke_type = int(float(stroke_type))
            
        prediction = {
            "filename": filename,
            "stroke": stroke,
            "stroke_type": stroke_type
        }
        
        self.tahminler.append(prediction)
    
    def generate_json(self) -> Dict[str, Any]:
        """
        JSON formatÄ±nda sonuÃ§ Ã¼ret
        
        Returns:
            Dict: YarÄ±ÅŸma formatÄ±nda JSON dictionary
        """
        return {
            "kunye": self.kunye,
            "tahminler": self.tahminler
        }
    
    def save_json(self, output_path: str):
        """
        JSON'u dosyaya kaydet
        
        Args:
            output_path: Ã‡Ä±ktÄ± dosyasÄ± yolu
        """
        result = self.generate_json()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"JSON dosyasÄ± '{output_path}' olarak kaydedildi.")
        print(f"Toplam {len(self.tahminler)} tahmin kaydedildi.")
    
    def validate_predictions(self):
        """
        Tahminleri doÄŸrula
        """
        errors = []
        
        for i, tahmin in enumerate(self.tahminler):
            # Dosya adÄ± kontrolÃ¼
            if not tahmin['filename'] or not isinstance(tahmin['filename'], str):
                errors.append(f"Tahmin {i}: GeÃ§ersiz dosya adÄ±")
            
            # Stroke deÄŸeri kontrolÃ¼
            if tahmin['stroke'] not in [0, 1]:
                errors.append(f"Tahmin {i}: stroke deÄŸeri 0 veya 1 olmalÄ±, mevcut: {tahmin['stroke']}")
            
            # Stroke deÄŸerinin int olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            if not isinstance(tahmin['stroke'], int):
                errors.append(f"Tahmin {i}: stroke deÄŸeri int formatÄ±nda olmalÄ±, mevcut tip: {type(tahmin['stroke'])}")
            
            # Stroke_type deÄŸeri kontrolÃ¼
            if tahmin['stroke_type'] not in [0, 1, 3]:
                errors.append(f"Tahmin {i}: stroke_type deÄŸeri 0, 1 veya 3 olmalÄ±, mevcut: {tahmin['stroke_type']}")
            
            # Stroke_type deÄŸerinin int olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            if not isinstance(tahmin['stroke_type'], int):
                errors.append(f"Tahmin {i}: stroke_type deÄŸeri int formatÄ±nda olmalÄ±, mevcut tip: {type(tahmin['stroke_type'])}")
        
        if errors:
            print("UYARILAR:")
            for error in errors:
                print(f"- {error}")
        else:
            print("TÃ¼m tahminler geÃ§erli!")
        
        return len(errors) == 0


# -----------------------------
# StrokeViT Model
# -----------------------------
class StrokeViT(nn.Module):
    def __init__(self, num_classes=1):
        super(StrokeViT, self).__init__()
        self.resnet = timm.create_model("resnet50", pretrained=True, num_classes=0, global_pool="avg")
        self.vit = timm.create_model("vit_small_patch16_224", pretrained=True, num_classes=0, global_pool="")
        self.fc = nn.Linear(2048 + self.vit.embed_dim, num_classes)

    def forward(self, x):
        res_feat = self.resnet(x)
        vit_feat = self.vit.forward_features(x)

        if vit_feat.dim() == 4:       # [B, C, H, W]
            vit_feat = torch.flatten(vit_feat, 1)
        elif vit_feat.dim() == 3:     # [B, N, C]
            vit_feat = vit_feat.mean(dim=1)

        combined = torch.cat((res_feat, vit_feat), dim=1)
        out = self.fc(combined)
        return out


def predict_for_competition(model_path: str, test_data_path: str, takim_adi: str, takim_id: str, 
                          output_json_path: str, threshold: float = 0.3, batch_size: int = 8):
    """
    StrokeViT modeli ile yarÄ±ÅŸma iÃ§in tahmin yap ve JSON olarak kaydet
    """
    print(f"ğŸš€ StrokeViT ile yarÄ±ÅŸma tahminleri baÅŸlatÄ±lÄ±yor...")
    print(f"Model: {model_path}")
    print(f"Test Data: {test_data_path}")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # Transform
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
    
    # Modeli yÃ¼kle
    model = StrokeViT(num_classes=1)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    print("âœ… Model yÃ¼klendi")
    
    # JSON generator'Ä± baÅŸlat
    generator = CompetitionJSONGenerator(
        takim_adi=takim_adi,
        takim_id=takim_id,
        aciklama="StrokeViT Hybrid Model (ResNet50 + ViT)",
        versiyon="v1.0"
    )
    
    # Test dosyalarÄ±nÄ± bul
    all_files = glob.glob(os.path.join(test_data_path, '*.png'))
    if not all_files:
        all_files = glob.glob(os.path.join(test_data_path, '**', '*.png'), recursive=True)
    
    all_files = sorted(all_files)
    print(f"ğŸ“ {len(all_files)} PNG dosyasÄ± bulundu")
    
    if len(all_files) == 0:
        print("âŒ HiÃ§ PNG dosyasÄ± bulunamadÄ±!")
        return
    
    # Ä°lk birkaÃ§ dosya adÄ±nÄ± gÃ¶ster
    print("ğŸ“„ Bulunan dosyalardan Ã¶rnekler:")
    for i, f in enumerate(all_files[:5]):
        print(f"  {i+1}. {os.path.basename(f)}")
    if len(all_files) > 5:
        print(f"  ... ve {len(all_files)-5} dosya daha")
    
    # Tahminleri topla
    all_predictions = []
    all_filenames = []
    
    with torch.no_grad():
        for i in range(0, len(all_files), batch_size):
            batch_files = all_files[i:i+batch_size]
            batch_images = []
            batch_names = []
            
            for file_path in batch_files:
                try:
                    img = Image.open(file_path).convert('RGB')
                    img_tensor = transform(img)
                    batch_images.append(img_tensor)
                    batch_names.append(os.path.basename(file_path))
                except Exception as e:
                    print(f"âš ï¸  Dosya okuma hatasÄ± {file_path}: {e}")
                    continue
            
            if len(batch_images) == 0:
                continue
                
            # Batch'i hazÄ±rla ve tahmin yap
            batch_tensor = torch.stack(batch_images).to(device)
            outputs = model(batch_tensor)
            raw_probs = torch.sigmoid(outputs).cpu().numpy().flatten()
            
            # MODEL TERSÄ°NE EÄÄ°TÄ°LDÄ°ÄÄ° Ä°Ã‡Ä°N PROBABÄ°LÄ°TY'YÄ° TERSÄ°NE Ã‡EVÄ°R
            probs = 1 - raw_probs
            
            # DEBUG: Ä°lk batch'te detay gÃ¶ster
            if i == 0:
                print(f"\nğŸ” Ä°lk {len(probs)} tahmin (model tersine eÄŸitilmiÅŸ):")
                for j, (name, raw_p, final_p) in enumerate(zip(batch_names, raw_probs, probs)):
                    pred = 1 if final_p >= threshold else 0
                    print(f"  {name}: raw={raw_p:.4f} -> final={final_p:.4f} -> {'STROKE' if pred==1 else 'NO_STROKE'}")
            
            all_predictions.extend(probs)
            all_filenames.extend(batch_names)
            
            if (i // batch_size + 1) % 10 == 0:
                print(f"ğŸ“Š Ä°ÅŸlenen: {min(i + batch_size, len(all_files))}/{len(all_files)}")
    
    print(f"âœ… Toplam {len(all_predictions)} tahmin tamamlandÄ±")
    
    # Probability istatistikleri
    probs_array = np.array(all_predictions)
    print(f"\nğŸ” Final Probability Ä°statistikleri (tersine Ã§evrilmiÅŸ):")
    print(f"  Min: {probs_array.min():.4f}")
    print(f"  Max: {probs_array.max():.4f}")
    print(f"  Mean: {probs_array.mean():.4f}")
    print(f"  Threshold ({threshold}) Ã¼stÃ¼: {(probs_array >= threshold).sum()}/{len(probs_array)}")
    
    # JSON'a ekle - DÄ°REKT BINARY DÃ–NÃœÅÃœM YAP
    binary_predictions = (probs_array >= threshold).astype(int)
    
    print(f"\nğŸ” Binary dÃ¶nÃ¼ÅŸÃ¼m kontrolÃ¼:")
    print(f"  Threshold: {threshold}")
    print(f"  Binary 1 sayÄ±sÄ±: {binary_predictions.sum()}/{len(binary_predictions)}")
    print(f"  Ä°lk 10 binary sonuÃ§: {binary_predictions[:10]}")
    
    # Manuel olarak ekle - load_from_model_output fonksiyonu sorunlu
    for filename, binary_pred in zip(all_filenames, binary_predictions):
        generator.add_prediction(filename, int(binary_pred), 3)
    
    # DoÄŸrula ve kaydet
    if generator.validate_predictions():
        generator.save_json(output_json_path)
        print(f"ğŸ‰ YarÄ±ÅŸma JSON dosyasÄ± baÅŸarÄ±yla kaydedildi: {output_json_path}")
        
        # Ã–zet bilgileri gÃ¶ster
        stroke_count = sum(1 for p in generator.tahminler if p['stroke'] == 1)
        no_stroke_count = len(generator.tahminler) - stroke_count
        print(f"ğŸ“ˆ FINAL SONUÃ‡: {stroke_count} STROKE (+), {no_stroke_count} NO STROKE (-)")
        print(f"ğŸ¯ KullanÄ±lan threshold: {threshold}")
        print(f"ğŸ”„ Model tersine eÄŸitildiÄŸi iÃ§in probability tersine Ã§evrildi (1-prob)")
        
        # FarklÄ± threshold'larla Ã¶zet
        print(f"\nğŸ“Š FarklÄ± threshold'larla sonuÃ§lar:")
        for t in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:
            stroke_count_t = (probs_array >= t).sum()
            print(f"  Threshold {t:.1f}: {stroke_count_t} stroke pozitif")
        
        # JSON kontrolÃ¼ - ilk birkaÃ§ tahmin
        print(f"\nğŸ“‹ JSON'daki ilk 5 tahmin:")
        for i, tahmin in enumerate(generator.tahminler[:5]):
            print(f"  {tahmin['filename']}: stroke={tahmin['stroke']}")
            
    else:
        print("âŒ DoÄŸrulama baÅŸarÄ±sÄ±z!")


# Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu
def main():
    """
    Ana fonksiyon
    """
    print("=" * 60)
    print("STROKEViT YARIÅMA JSON HAZIRLAYICI - SON VERSÄ°YON")
    print("=" * 60)
    
    print("KULLANIM:")
    predict_for_competition(
        model_path="/home/comp5/ARTEK/SYZ_25_YARISMA/BIRINCI_GOREV/Morpheus/resnet50_strokevit_small/strokevit_best_model_small_resnet.pth",
        test_data_path="/home/comp5/ARTEK/SYZ_25_YARISMA/deneme_png",
        takim_adi="Morpheus",
        takim_id="568784", 
        output_json_path="final_competition_predictions.json",
        threshold=0.3,
        batch_size=8
    )


if __name__ == "__main__":
    main()